---
title: "About"
draft: false
---

<div style="font-size: 50px; font-weight: bold; text-align: center;">Welcome to HAISN!</div>

<br>

<div style="text-align: center;"> 
    <img src="/logo/haisn.png" alt="Logo of HAISN" style="display: block; margin: 0 auto; max-width: 100%; height: auto;">
</div>

<br>

We are the Hanoi AI Safety Network (HAISN), an organization established for curious university students
in Hanoi, Vietnam to meet and work towards safer AI.

We believe current AI development trends are are [highly unsafe](https://www.aisafety.com/), 
posing a real threat of [catastrophic risks](https://www.safe.ai/work/statement-on-ai-risk). 
Meanwhile, current work in AI safety is inadequate for addressing future AI risks.

This is why HAISN was founded!

We try to help advance the field of AI safety with various activities and programs. Our current activities include:

- **AI Safety Intro Fellowship**: A weekly introductory reading and discussion group to AI Safety.
Funded by [OpenPhilanthropy](https://www.openphilanthropy.org/).

- **Career Guidance**: Support for your research and future exploration, such as compute to run your 
AI experiments, pointers to relevant career opportunities, and access to a network of AI safety 
researchers.

- **Community Bookshelf**: Access to learning materials through our expansive community bookshelf.

- **Research Hackathons**: We facilitate monthly research hackathons in collaboration with 
[Apart Research](https://www.apartresearch.com/).
Funded by [OddlyNormal](https://oddly-podcast.com/).

Whether you're an AI developer, researcher, or just an enthusiast, please feel free to reach out to us! 

- [**LinkedIn**](https://www.linkedin.com/company/hanoi-ai-safety-network)
- [**Email**](mailto:jordnguyen43@gmail.com)

Let's all shape the future of safe and trustworthy AI!
