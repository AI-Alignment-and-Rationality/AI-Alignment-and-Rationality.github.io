---
title : 'Session 10: Hackathon'
date : 2024-05-09T20:58:07+07:00
draft : false 
---

## Hackathon description
üåè Join us to evaluate and mitigate societal challenges from AI  

Despite the many potential benefits of the technology (such as equalizing opportunity, creating wealth, and improving coordination), we are also facing significant risks from AI.

Together, we will be hacking away to demonstrate and mitigate the challenges that arise in AI, while trying to project these risks into the future.

## Summary

Sadly, the majority of group members were unavailable for the whole weekend due to exams or other personal reasons. 4 members participated in 3 projects linked below here:
- [GPT4 Is Righter Than GPT3.5 Replicating Findings on Political Bias in LLMs for non-Western Democracies](https://www.apartresearch.com/project/gpt-4-is-righter-than-gpt-3-5-replicating-findings-on-political-bias-in-llms-for-non-western-democracies), By Huu Khiem "Gumperto" Hoang, Jord Nguyen
- [Assessing Algorithmic Bias in Large Language Models' Predictions of Public Opinion Across Demographics](https://www.apartresearch.com/project/assessing-algorithmic-bias-in-large-language-models-predictions-of-public-opinion-across-demographics-6c5c4), By Khai Tran (purplechair), Sev Geraskin, Doroteya Stoyanova, Jord Nguyen
- [AI Politician](https://www.apartresearch.com/project/ai-politician), By David Abecassis, Felix Michalak, Nguyen Dang Nhat Anh (skrubz), Zhiyi Xu 

![jamming time](/image11.jpg) jamming away

![model agnostic interpretability presentation](/image7.jpg)
Break time presentation: Model agnostic interpretability presentation  
Jord demonstrated an interpretability agenda which he thought was interesting, based on [this presentation by Leap Labs](https://docs.google.com/presentation/d/17gu5t6CFhd_b0azqAgZFI1jxyLtM4_0r1MflQuVGk8A/edit)
