---
title : 'Session 7: Technical (&) Governance'
date : 2024-04-23T19:02:31+07:00
draft : false 
---

## Technical (&) Governance

- In the Technical stream, all of us built a better understanding of some of the foundational techniques and architectures used in modern AI systems by:
- Doing some basic research on neural networks and machine learning
  - Going through some questions on these topics in a few minutes
  - Discussing the implications of these answers for AI development, and sometimes, AI Safety
- For everyone interested in Mechanistic Interpretability, activities were:
  - Try to read and research further on the topics presented in one or more of the following articles/papers:
    - Zoom In: An Introduction to Circuits
    - Toy Models of Superposition
    - Towards Monosemanticity
    - Interpretability in the Wild
  - Then, attempt to:
    - Summarize what the central claim is. Express some uncertainty you may have.
    - Find evidence or arguments that support or reject the claim.
    - Answer some questions related to the reading.
- In the Governance stream, we:
  - Read through the “Intro to Governance Fundamentals”
  - Researched and tried to answer some questions related to recent developments in AI to get an idea of the landscape, mainly to see how fast it’s moving
  - After this, we each chose one of the following questions, spent 15 minutes researching and writing up a 1-page report on it. Then we presented what we could research to everyone and answered everyone’s questions:
    - What is the EU AI safety act about? How does this help prevent AI risks?
    - What is the current AI safety governance paradigm in developing countries?
    - What is Moore’s law? Does this still hold up to today? What does this mean for AI development growth?
    - Has there been any examples of AI misuse? What about accidents? What about misalignment? Distill and demonstrate them.