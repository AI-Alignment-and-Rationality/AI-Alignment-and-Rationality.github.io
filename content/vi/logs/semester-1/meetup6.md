---
title : ' Session 6: Scalable Oversight & New Members!  '
date : 2024-04-07T12:39:20+07:00
draft : false 
---
![discussion w/ new members](/image8.jpg)
## New members

- We spent some time introducing ourselves to the new members and letting the new members introduce themselves to us.
- We talked to each other about the basic argument of AI alignment and why it’s important
- We watched Robert Miles’ “Intro to AI Safety, Remastered” and “10 Reasons to Ignore AI Safety”

## x-risk Debate

- We debated with each other on whether the most important problems of AI Safety is short-medium-term (economic, sociopolitical) or long-term (irreversible turning point in human history), whether that problem would be infrastructural or existential.
- In the end we found agreement in the fact that working on AI Safety is an important endeavor, whether or not AI risk is existential.

## Scalable oversight

- We watched Robert Miles’ “Iterated amplification and distillation” and read through week 4 of the AI safety fundamentals course
