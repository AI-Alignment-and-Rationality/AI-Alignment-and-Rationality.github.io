---
title: "Session 11: Intro to Agent Foundations + more self research"
date: 2024-06-23T15:21:39+07:00
draft: false 
---

## Agent foundations

We found this textbook— [AISF Alignment Express](https://docs.google.com/document/d/1bPKt2xIebDfct9YSzfGPkc0PW5w4zT61m5Ob3SkJLnQ/edit) —which seems quite useful for a more structured and centralized way of getting into introductory AI Safety than the AI Safety Fundamentals Course. This is the resource we used for the week to learn about agent foundations.

- We spent around 30 minutes reading through [Chapter 9: Agent Foundations](https://docs.google.com/document/d/1z4CwGDUzHvPvfXNxyfDaIfh9kK1JBJWEcfdGUutfJY0/edit) and discussed some basic concepts and definitions.
- After that we listened through a talk delivered by Eliezer Yudkowsky, called [AI Alignment: Why It's Hard, and Where to Start](https://youtu.be/EUjc1WuyPT8) for a more gentle introduction in agent foundations, as well as to reinforce some fundamental ideas about AI alignment as a whole.
